# Adversarial-attacks-and-defenses
A curated list of adversarial learning resources

	
Some current models are quite vulnerable to adversarial examples, for example, inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. 

Adversarial examples expose regions of the input space where the model performs poorly, which can aid in understanding and improving the model. 

By using these examples as training data, adversarial training learns models that are more robust, and may even perform better on non-adversarial examples. 


## Table of Contents
### Attacks
 - [CV](#CV)
 - [NLP](#NLP)
 - [RL](#RL)
### Defenses
 


## CV
 * 
